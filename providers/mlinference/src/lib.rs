#![allow(dead_code)]

use std::{collections::HashMap};
use thiserror::Error as ThisError;
use serde::{Deserialize, Serialize};
use wasmcloud_interface_mlinference::{ ResultStatus };

mod metadata;
pub use metadata::{ModelDefinition, get_first_member_of};
mod settings;
pub use settings::{load_settings, ModelSettings};
mod hashmap_ci;
pub (crate) use hashmap_ci::make_case_insensitive;

/// GraphEncoding
#[derive(Clone, Debug, Default, Deserialize, Eq, PartialEq, Serialize)]
pub struct GraphEncoding(u8);

impl GraphEncoding {
    pub const GRAPH_ENCODING_OPENVINO: u8 = 0;
    pub const GRAPH_ENCODING_ONNX:     u8 = 1;
}

/// ExecutionTarget
#[derive(Clone, Debug, Default, Deserialize, Eq, PartialEq, Serialize)]
pub struct ExecutionTarget(u8);

impl ExecutionTarget {
    pub const EXECUTION_TARGET_CPU: u8 = 0;
    pub const EXECUTION_TARGET_GPU: u8 = 1;
    pub const EXECUTION_TARGET_TPU: u8 = 2;
}

/// TensorType
#[derive(Clone, Debug, Default, Deserialize, Eq, PartialEq, Serialize)]
pub struct TensorType(u8);

impl TensorType {
    pub const F16: u8 = 0;
    pub const F32: u8 = 1;
    pub const  U8: u8 = 2;
    pub const I32: u8 = 3;
}

/// Graph
#[derive(Clone, Debug, Default, Deserialize, Eq, PartialEq, Serialize)]
pub struct Graph {
    pub graph: u32,
}

/// GraphExecutionContext
#[derive(Clone, Debug, Default, Deserialize, Eq, PartialEq, Serialize)]
pub struct GraphExecutionContext {
    pub gec: u32,
}

pub type BindlePath = String;
pub type ModelName = String;
pub type ModelZoo = HashMap<ModelName, ModelContext>;

#[derive(Clone, Debug, Default, PartialEq, Deserialize)]
pub struct ModelContext {
    pub bindle_url: BindlePath,
    pub encoding: GraphEncoding,
    pub tensor_type: TensorType,
    pub session: GraphExecutionContext,
    pub graph: Graph
}

impl ModelContext {
    // /// load model data
    // pub fn load_model_data(&self, model: Vec<u8>) {}

    /// load metadata
    pub fn load_metadata(mut self, metadata: ModelMetadata) -> Result<ModelContext, Error> {

        self.encoding = match metadata.graph_encoding.as_str() {
            "ONNX" => Ok(GraphEncoding(GraphEncoding::GRAPH_ENCODING_ONNX)),
            _      => Err(())
        }.map_err(|_| Error::Settings(format!("invalid 'graph_encoding'")))?;

        self.tensor_type = match metadata.tensor_type.as_str() {
            "F16" => Ok(TensorType(TensorType::F16)),
            "F32" => Ok(TensorType(TensorType::F32)),
             "U8" => Ok(TensorType(TensorType::U8)),
            "I32" => Ok(TensorType(TensorType::I32)),
               _  => Err(()),
        }.map_err(|_| Error::Settings(format!("invalid 'tensor_type'")))?;

      


        // self.execution_target = match metadata.execution_target.as_str() {
        //     "CPU" => Ok(ExecutionTarget(ExecutionTarget::EXECUTION_TARGET_CPU)),
        //     "GPU" => Ok(ExecutionTarget(ExecutionTarget::EXECUTION_TARGET_GPU)),
        //     "TPU" => Ok(ExecutionTarget(ExecutionTarget::EXECUTION_TARGET_TPU)),
        //        _  => Err(()),
        // }.map_err(|_| Error::Settings(format!("invalid 'execution_target'")))?;


        Ok(self)
    }
}

#[derive(Serialize, Deserialize)]
pub struct ModelMetadata {
    pub model_name: Option<String>,
    pub graph_encoding: String,
    pub execution_target: String,
    pub tensor_type: String,
    pub tensor_dimensions_in: Option<Vec<u32>>,
    pub tensor_dimensions_out: Option<Vec<u32>>
}

impl ModelMetadata {
    /// load metadata from json
    pub fn from_json(data: &[u8]) -> Result<Self, Error> {
        serde_json::from_slice(data).map_err(|e| Error::Settings(format!("invalid json: {}", e)))
    }
}

/// errors generated by this crate
#[derive(ThisError, Debug)]
pub enum Error {
    #[error("invalid parameter: {0}")]
    InvalidParameter(String),

    #[error("problem reading settings: {0}")]
    Settings(String),

    #[error("provider startup: {0}")]
    Init(String),

    #[error("deserializing settings: {0}")]
    SettingsToml(toml::de::Error),
}

/// generates a valid result
/// TODO__CB__ could be some 'default'?
pub fn get_valid_status() -> ResultStatus {
    ResultStatus {
        has_error: false,
        error: None
    }
}

/// removes all remaining state for given models
/// TODO__CB__
pub fn drop_state(_mz: ModelZoo) -> () {}